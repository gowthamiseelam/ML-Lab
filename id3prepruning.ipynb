{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-pruned Tree: {'Outlook': {'Overcast': 'Yes', 'Rain': 'Yes', 'Sunny': 'Yes'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'pre_pruned_decision_tree.png'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from graphviz import Digraph\n",
    "\n",
    "def visualize_tree(tree, features, parent_name='', graph=None, is_root=True):\n",
    "    if graph is None:\n",
    "        graph = Digraph()\n",
    "        graph.node(name='root', label=next(iter(tree)), shape='ellipse')\n",
    "        parent_name = 'root'\n",
    "\n",
    "    if isinstance(tree, dict):\n",
    "        for k, v in tree.items():\n",
    "            if isinstance(v, dict):\n",
    "                node_name = f'{k}'\n",
    "                if is_root:\n",
    "                    is_root = False\n",
    "                else:\n",
    "                    if node_name not in features:\n",
    "                        graph.node(name=node_name, label=str(k), shape='box')\n",
    "                    else:\n",
    "                        graph.node(name=node_name, label=str(k), shape='ellipse')\n",
    "                graph.edge(parent_name, node_name)\n",
    "                visualize_tree(v, features, node_name, graph, is_root)\n",
    "            else:\n",
    "                if v == 'Yes' or v == 'No':\n",
    "                    node_name = f'{k}'\n",
    "                    if node_name not in features:\n",
    "                        graph.node(name=node_name, label=str(k), shape='box')\n",
    "                    else:\n",
    "                        graph.node(name=node_name, label=str(k), shape='ellipse')\n",
    "                    graph.edge(parent_name, node_name)\n",
    "                    node_name = f'{k}_{v}'\n",
    "                    graph.node(name=node_name, label=str(v), shape='diamond')\n",
    "                    graph.edge(str(k), node_name)\n",
    "    else:\n",
    "        if tree == 'Yes' or tree == 'No':\n",
    "            node_name = f'{parent_name}_{tree}'\n",
    "            graph.node(name=node_name, label=str(tree), shape='diamond')\n",
    "            graph.edge(parent_name, node_name)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def entropy(target_col):\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    entropy_value = np.sum([(-counts[i]/np.sum(counts)) * np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy_value\n",
    "\n",
    "def info_gain(data, split_attribute_name, target_name=\"class\"):\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    vals, counts = np.unique(data[split_attribute_name], return_counts=True)\n",
    "    weighted_entropy = np.sum([(counts[i]/np.sum(counts)) * entropy(data.where(data[split_attribute_name] == vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    information_gain = total_entropy - weighted_entropy\n",
    "    return information_gain\n",
    "\n",
    "def id3(data, original_data, features, target_attribute_name=\"class\", parent_node_class=None, max_depth=5, min_samples_split=2, depth=0):\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(original_data[target_attribute_name])[np.argmax(np.unique(original_data[target_attribute_name], return_counts=True)[1])]\n",
    "    elif len(features) == 0 or depth >= max_depth or len(data) < min_samples_split:\n",
    "        return parent_node_class\n",
    "    else:\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])]\n",
    "        item_values = [info_gain(data, feature, target_attribute_name) for feature in features]\n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "        tree = {best_feature: {}}\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            subtree = id3(sub_data, original_data, features, target_attribute_name, parent_node_class, max_depth, min_samples_split, depth + 1)\n",
    "            tree[best_feature][value] = subtree\n",
    "        return tree\n",
    "\n",
    "# Examples:\n",
    "training_data = pd.DataFrame({\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'Target': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "})\n",
    "# training_data = pd.DataFrame({\n",
    "#     'Feature1': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'C'],\n",
    "#     'Feature2': ['X', 'X', 'Y', 'X', 'Y', 'Y', 'X', 'X', 'Y', 'Y'],\n",
    "#     'Target': ['Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes']\n",
    "# })\n",
    "feature_columns = training_data.columns[:-1].to_list()\n",
    "target_column = 'Target'\n",
    "decision_tree = id3(training_data, training_data, feature_columns, target_column, max_depth=1, min_samples_split=3)\n",
    "print(\"Pre-pruned Tree:\", decision_tree)\n",
    "\n",
    "# Visualize the pre-pruned tree\n",
    "graph = visualize_tree(decision_tree, feature_columns)\n",
    "graph.render('pre_pruned_decision_tree', format='png', cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
